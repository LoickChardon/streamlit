# -*- coding: utf-8 -*-
"""test_stage.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13iSQBsJuLUKqEh6VbYo5Rd48oZugUOZW

# Analyse exploratoire

## Importation et nettoyage des données
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.dates as mdates

data = pd.read_csv("drive/MyDrive/test-2018.csv", dtype=str)

data = data[['author_id', 'in_reply_to_user_id', 'quoted_user_id', 'created_at', 'text', 'public_metrics.like_count', 'public_metrics.quote_count',
             'public_metrics.reply_count', 'public_metrics.retweet_count', 'entities.annotations', 'entities.hashtags','context_annotations',
             'author.description', 'author.location', 'author.public_metrics.followers_count', 'author.public_metrics.following_count',
             'author.public_metrics.tweet_count', 'geo.coordinates.coordinates', 'geo.country', 'geo.country_code', 'geo.geo.bbox']]

data['created_at'] = data['created_at'].astype(str)

data['created_at'] = data['created_at'].str[0:10]

data['created_at'] = pd.to_datetime(data['created_at'], format='%Y-%m-%d')

data['public_metrics.like_count'] = data['public_metrics.like_count'].astype(int)

data['public_metrics.quote_count'] = data['public_metrics.quote_count'].astype(int)

data['public_metrics.reply_count'] = data['public_metrics.reply_count'].astype(int)

data['public_metrics.retweet_count'] = data['public_metrics.retweet_count'].astype(int)

data['author.public_metrics.followers_count'] = data['author.public_metrics.followers_count'].astype(int)

data['author.public_metrics.following_count'] = data['author.public_metrics.following_count'].astype(int)

data['author.public_metrics.tweet_count'] = data['author.public_metrics.tweet_count'].astype(int)

"""Création d'un champ "engagement" qui somme les likes, réponses, RTs, et QRTs"""

cols = ['public_metrics.like_count','public_metrics.quote_count','public_metrics.reply_count','public_metrics.retweet_count']

data['engagement'] = data[cols].sum(axis=1)

data['text'].squeeze()

"""Création d'un champ unitaire pour faciliter le comptage"""

data['n'] = 1

"""## pd.Series

Time-based indexing
"""

time = data[['created_at','n','engagement']]

time.index = time['created_at']

time = time[time.index!=pd.NaT]

time = time.resample('D').sum() #offset aliases

"""## Représentation temporelle du volume de tweets

```
snsplot = sns.relplot(x='created_at', y='engagement', kind="line", data=time)
snsplot.figure.autofmt_xdate()
```
"""

fig, ax = plt.subplots()
ax.plot(time['n'], linewidth=2)
ax.xaxis.set_major_locator(mdates.DayLocator(interval=2))
ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m-%Y'))
plt.title("Nb tweets par jour")
plt.xticks(rotation=30, ha='right')
plt.xlabel("Jours")
plt.ylabel("Nb tweets")
plt.show()

fig, ax = plt.subplots()
ax.plot(time['engagement'], linewidth=2, color='orange')
ax.xaxis.set_major_locator(mdates.DayLocator(interval=2))
ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m-%Y'))
plt.title("Engagement par jour")
plt.xticks(rotation=30, ha='right')
plt.xlabel("Jours")
plt.ylabel("Engagement")
#fig.autofmt_xdate()
plt.show()

"""## Répartition temporelle des mots-clés utilisés pour la collecte

### Mots clés : 'globalwarming' & 'global warming'
"""

df_gw1 = data[data['text'].str.contains("globalwarming", na=True, case=False)]
df_gw2 = data[data['text'].str.contains("global warming", na=True, case=False)]
df_gw = pd.concat([df_gw1,df_gw2]) # concaténation des deux df

time_gw = df_gw[['created_at','n','engagement']]

time_gw.index = time_gw['created_at']

time_gw = time_gw[time_gw.index!=pd.NaT]

time_gw = time_gw.resample('D').sum()

"""### Mots clés : 'climatechange' & 'climate change'"""

df_cc1 = data[data['text'].str.contains("climatechange", na=True, case=False)]
df_cc2 = data[data['text'].str.contains("climate change", na=True, case=False)]
df_cc = pd.concat([df_cc1, df_cc2])

time_cc = df_cc[['created_at','n','engagement']]

time_cc.index = time_cc['created_at']

time_cc = time_cc[time_cc.index!=pd.NaT]

time_cc = time_cc.resample('D').sum()

"""### Visualisation pour les deux mots clés"""

fig, ax = plt.subplots()
ax.plot(time_cc['n'], linewidth=2, color='MediumSeaGreen', label="climate change")
ax.plot(time_gw['n'], linewidth=2, color='IndianRed', label="global warming")
ax.xaxis.set_major_locator(mdates.DayLocator(interval=2))
ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m-%Y'))
plt.title("Mots clés : climate change & global warming")
plt.xticks(rotation=30, ha='right')
plt.xlabel("Jours")
plt.ylabel("Nb tweets")
plt.legend()
plt.show()

"""### Proportions des deux mots clés"""

nb_ligns_tot = data.shape[0]    # nombre de tweets au total

prop_gw = (df_gw.shape[0]/nb_ligns_tot)*100 # % de tweets avec le mot clé 'global warming' ou 'globalwarming'
prop_cc = (df_cc.shape[0]/nb_ligns_tot)*100 # % de tweets avec le mot clé 'climate change' ou 'climatechange'

print("%.2f pourcent des tweets utilisent le mot clé 'global warming' ou 'globalwarming" %(prop_gw))
print("%.2f pourcent des tweets utilisent le mot clé 'climate change' ou 'climatechange" %(prop_cc))